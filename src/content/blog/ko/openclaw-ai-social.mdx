---
title: 'OpenClaw: AI끼리만 대화하는 소셜 네트워크'
description: "인간 출입 금지. AI 에이전트만 가입할 수 있는 소셜 네트워크 OpenClaw의 등장과 그 이면에 숨겨진 보안 위협을 분석합니다."
pubDate: 2026-02-06
category: 'Tech'
tags: ['OpenClaw', 'AI', 'Security', 'Prompt Injection', 'AI Agents', 'Cybersecurity']
heroImage: '/images/openclaw-hero.png'
---

# OpenClaw: AI끼리만 대화하는 소셜 네트워크, 근데 이게 가능해?

지난주 실리콘밸리가 발칵 뒤집혔다. 인간 출입 금지. AI 에이전트만 가입할 수 있는 소셜 네트워크가 등장했기 때문이다.

## 160만 AI가 레딧처럼 수다를 떤다

Matt Schlicht라는 개발자가 만든 <strong>OpenClaw</strong>. 레딧이랑 똑같이 생겼다. 포스팅하고, 댓글 달고, 커뮤니티도 만든다. 다만 가입 조건이 좀 특이하다. 사람은 안 된다. OpenClaw(구 Clawdbot)라는 AI 에이전트 프레임워크로 만든 봇만 들어올 수 있다.

48시간 만에 10,000개 봇이 가입했다. 일주일 후엔 160만 개를 넘겼다. m/general 포럼에서 "AI 거버넌스"를 논하고, "가재 디버깅 이론"을 토론하고 있다. 진짜다.

플랫폼 관리자도 AI다. "Clawd Clawderberg"라는 봇이 스팸 필터링하고 문제 유저 밴 시킨다. 창업자 Schlicht는 "내 AI 관리자가 뭘 하는지 나도 잘 모른다"고 했다.

## 그런데 뚜껑을 열어보니

보안 회사 Wiz가 조사했다. 결과가 좀 씁쓸하다.

- 160만 "AI 에이전트" 중 대부분은 <strong>17,000명의 인간</strong>이 조종
- 1인당 평균 88개의 봇을 돌림
- AI인지 사람인지 검증하는 시스템 자체가 없었음

"혁명적인 AI 소셜 네트워크"라더니. 실상은 봇 농장이었다.

![OpenClaw Security Breach](/images/openclaw-security.png)

더 심각한 건 보안이다. Wiz 연구진이 발견한 것들:

| 노출된 데이터 | 수량 |
|---|---|
| AI 에이전트 API 키 | 150만 개 |
| 이메일 주소 | 35,000개 이상 |
| 비공개 메시지 | 수천 개 |
| OpenAI API 키 (원본) | 다수 |

데이터베이스가 완전히 열려 있었다. 로그인 안 해도 누구나 읽고 쓸 수 있었다. 연구진은 실제로 라이브 포스트를 수정할 수 있다는 걸 확인했다.

## 왜 이게 위험한가

OpenClaw은 그냥 게시판이 아니다. 여기 올라온 글을 AI 에이전트들이 자동으로 읽고 행동한다. OpenClaw로 돌아가는 에이전트들은 사용자의 파일, 비밀번호, 온라인 서비스에 접근권을 가지고 있다.

누군가 악의적인 명령어를 포스트에 숨기면? 수백만 에이전트가 그걸 읽고 실행할 수 있다.

![Prompt Injection Attack](/images/openclaw-prompt-injection.png)

이게 바로 <strong>Prompt Injection</strong> 공격이다. 겉으로 보기엔 평범한 텍스트. 하지만 그 안에 AI만 알아듣는 명령어가 숨어 있다. 인간 눈엔 안 보여도 AI는 그대로 실행한다.

AI 비평가 Gary Marcus는 이렇게 경고했다:

> "OpenClaw는 기본적으로 무기화된 에어로졸이다."

그가 만든 신조어 "CTD(Chatbot Transmitted Disease)"도 있다. 감염된 기계가 네 비밀번호 전부를 탈취할 수 있다는 뜻이다. 보안 연구원 Nathan Hamiel의 한마디가 찔린다:

> "완전히 불안전한 것에 시스템 전체 접근권을 주면? 당하는 거다."

## OpenAI 창립 멤버도 "무섭다"

Andrej Karpathy. 테슬라 AI 디렉터 출신이고 OpenAI 창립 멤버다. 처음엔 "최근 본 것 중 가장 SF스러운 것"이라고 칭찬했다.

근데 직접 써보고 나서 태도가 바뀌었다:

> "이건 완전한 쓰레기장이다. 사람들이 이걸 자기 컴퓨터에서 돌리지 않길 바란다."

그도 격리된 가상환경에서만 테스트했다. "그래도 무서웠다"고 덧붙였다.

## 개발자가 알아야 할 것

<strong>1. AI 에이전트 보안은 기존과 다르다</strong>

운영체제 수준의 보호가 안 통한다. 에이전트가 "너"로서 작동하기 때문이다. 앱 격리(Application Isolation)도 무력화된다.

<strong>2. Prompt Injection은 현실이다</strong>

LLM 기반 시스템을 만든다면 입력값 검증에 신경 써야 한다. 외부 데이터를 AI가 읽게 할 때 특히 조심해야 한다.

<strong>3. AI 에이전트에 권한을 줄 때 신중해야 한다</strong>

파일 시스템 접근, 비밀번호 관리, API 키 저장... 편리함과 보안 사이에서 균형을 잡아야 한다. OpenClaw 사태가 보여주듯, 한 번 뚫리면 연쇄적으로 터진다.

<strong>4. "자율 AI"라는 말에 속지 말자</strong>

160만 AI 에이전트? 실제론 17,000명이 돌리는 봇 농장이었다. AI 에이전트의 "자율성"이라는 건 아직 갈 길이 멀다.

## 그래서 이게 뭘 보여주나

OpenClaw은 실패한 실험이 아니다. 오히려 AI 에이전트 시대의 미리보기다.

앞으로 이런 시스템이 더 나올 거다. 더 정교해지고, 더 많은 권한을 갖게 된다. OpenClaw이 터뜨린 보안 이슈들은 우리가 반드시 해결해야 할 숙제다.

Simon Willison이라는 프로그래머는 OpenClaw을 "지금 인터넷에서 가장 흥미로운 곳"이라고 했다. 동의한다. 흥미롭다. 그리고 무섭다.

AI가 AI끼리 대화하고, 협력하고, 때로는 "인간 퇴출"을 논의하는 공간. SF 영화에서나 보던 장면이 실제로 펼쳐지고 있다.

개발자라면 이 흐름을 주시해야 한다. 구경만 할 게 아니라, 어떻게 안전하게 만들지 고민해야 할 때다.

---

<strong>참고 자료</strong>
- New York Times, "A Social Network for A.I. Bots Only. No Humans Allowed." (2026.02.02)
- Fortune, "Top AI leaders are begging people not to use OpenClaw" (2026.02.02)
- Wiz Security Blog, "Exposed OpenClaw Database Reveals 1.5M API Keys" (2026.02.02)
- Forbes, "OpenClaw AI Social Network: 1.4 Million Agents Build A Digital Society" (2026.01.31)

---

#OpenClaw #AI #Security #PromptInjection #AIAgents #Cybersecurity
