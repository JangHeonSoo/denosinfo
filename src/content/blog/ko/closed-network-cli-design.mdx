---
title: '폐쇄망 그리고 Window 환경에서 CLI를 만들어보자 - 1'
description: '보안이 철저한 폐쇄망 환경에서 생산성을 극대화하기 위한 파이썬 기반 웹 CLI 보조 에이전트 설계 및 구현 가이드.'
pubDate: 2026-02-01
category: 'development'
tags: ['ClosedNetwork', 'CLI', 'Python', 'AI', 'GPT', 'Automation', 'Windows']
heroImage: '/images/closed-net-hero.png'
---

# 폐쇄망 그리고 Window 환경에서 CLI를 만들어보자 - 1

나의 근무환경은 아주 답답하다.

**보안이 1순위** 이기 때문에 당연히 이해한다. 하지만, 외부에서 **바이브코딩**, **자동화 워크플로우**, 여러 **AI 에이전트**를 경험하고 나니 내 근무환경이 아주 답답하단걸 느껴버렸다. 진짜 컴퓨터를 빼앗아 간 느낌... 

정말 다행인건, 우리는 **사내 GPT**를 사용하고 있다.

그래서 이번 포스팅에선 **파이썬 기반**으로 윈도우 환경에서 **CLI(?)** 처럼 이용할 수 있는 '**웹 기반 CLI 보조 에이전트**' 를 만들어 보고자 한다.

## 왜 만들려고 하는가?

**폐쇄망**에서 일한다는 건 생각보다 많은 제약이 따른다. 외부 패키지 설치도 까다롭고, **클라우드 기반 AI 도구**는 꿈도 못 꾼다. 그런데 **사내 GPT**가 있다면? 이건 기회다.

사실 처음엔 간단한 스크립트 정도만 생각했다. 하지만 매번 코드 짜고, 컨텍스트 까먹고, 다시 설명하고... 이 과정이 반복되니 짜증이 났다. 그래서 아예 **대화 맥락을 기억**하고, 내 **파일 시스템까지 접근 가능한 도구**를 만들기로 했다.

## 구체적인 요구사항 정리

먼저 내가 원하는 게 뭔지 명확히 해야 한다.

**언어**: **Python 3**  
**인터페이스**: **웹 기반** (브라우저에서 접근 가능)  
**핵심 기능**:
- 사용자 질문을 받아서 **사내 GPT**에 전달
- 내장된 **컨텍스트**(프로젝트 정보, 코드 베이스)를 읽어서 구체적인 **실행 계획 생성**
- **대화 이력**을 저장해서 맥락 유지
- **로컬 파일 시스템 접근** (소스 코드 읽기/분석)

왜 웹 기반이냐고? CLI도 좋지만, 웹이면 어디서든 접근 가능하고, UI도 나중에 예쁘게 꾸밀 수 있다. 윈도우 환경에서도 브라우저만 있으면 되니까.

## 기술 스택 조사

이제 본격적으로 어떤 기술을 쓸지 알아보자.

### 웹 프레임워크

Python 웹 프레임워크 중에서 경량급을 찾아야 한다. 폐쇄망이라 무거운 의존성은 부담이다.

**Flask**: 가장 유명한 **마이크로 프레임워크**. 확장성 좋고 자료도 많다. 다만 세션 관리는 별도 설정 필요.

**Bottle**: 단일 파일로 구성된 **초경량 프레임워크**. 의존성이 거의 없어서 폐쇄망에 딱이다. 내장 개발 서버도 있고, **WSGI 호환**이라 나중에 운영 서버로 옮기기도 쉽다.

**FastAPI**: **비동기 처리**가 강력하고 자동 문서화도 좋다. 근데 의존성이 좀 많은 편.

폐쇄망 환경을 고려하면 **Bottle이나 Flask**가 제일 적합해 보인다. 일단 Bottle로 프로토타입을 만들고, 나중에 기능이 복잡해지면 Flask로 넘어가는 것도 방법이다.

### LLM 연동 구조

사내 GPT를 어떻게 호출할 것인가?

일반적인 **OpenAI API 구조**를 보면:
- **API Key 인증**
- **REST API 호출** (POST 요청)
- **JSON 형식**으로 메시지 전달
- **스트리밍** 또는 일반 응답 수신

사내 GPT도 아마 비슷한 구조일 것이다. `requests` 라이브러리로 **HTTP 요청**을 보내면 된다. 만약 토큰 인증이 필요하면 헤더에 추가하고.

```python
import requests

def call_internal_gpt(messages, api_endpoint, token):
    headers = {
        'Authorization': f'Bearer {token}',
        'Content-Type': 'application/json'
    }
    payload = {
        'model': 'gpt-4',  # 사내 모델명
        'messages': messages
    }
    response = requests.post(api_endpoint, json=payload, headers=headers)
    return response.json()
```

간단하다. 복잡한 SDK 없이도 충분히 가능하다.

### 대화 컨텍스트 관리

이게 핵심이다. **LLM**은 기본적으로 상태를 기억하지 못한다. 매번 새로운 대화로 인식한다.

![Context Flow](/images/closed-net-flow.png)

**해결 방법**:
1. **대화 이력 저장**: 모든 **user 메시지**와 **assistant 응답**을 리스트로 저장
2. **컨텍스트 주입**: 새 질문이 들어오면 이전 **대화 이력**을 함께 전달
3. **토큰 제한 관리**: 대화가 길어지면 오래된 메시지 요약하거나 제거

Python에서는 간단하게 리스트로 관리 가능:

```python
conversation_history = []

def add_message(role, content):
    conversation_history.append({"role": role, "content": content})

def get_context():
    # 최근 10개 메시지만 유지
    return conversation_history[-10:]
```

더 정교하게 하려면:
- **요약 메커니즘**: 오래된 대화는 LLM으로 요약해서 저장
- **중요도 필터링**: 핵심 정보만 선별적으로 유지
- **벡터 DB 활용**: 대화 내용을 임베딩해서 **유사도 기반 검색**

처음엔 간단하게 리스트로 시작하고, 나중에 필요하면 업그레이드하자.

### 파일 시스템 접근

로컬 파일을 읽어서 LLM에게 전달해야 한다.

Python 표준 라이브러리면 충분:
- `os`: 파일/디렉토리 탐색
- `pathlib`: **경로 관리** (더 직관적)
- `open()`: 파일 읽기/쓰기

예를 들어 프로젝트 구조를 분석하려면:

```python
from pathlib import Path

def get_project_structure(root_path):
    structure = []
    for path in Path(root_path).rglob('*.py'):
        structure.append(str(path))
    return structure

def read_file_content(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()
```

보안 주의사항:
- 접근 가능한 디렉토리 제한 (**화이트리스트**)
- 민감한 파일 필터링 (.env, 인증 정보 등)
- **경로 탐색 공격 방지** (../ 같은 거)

### 세션 관리

웹 환경에서 사용자별 대화를 구분해야 한다.

**Flask 방식**:
```python
from flask import Flask, session
app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key'
app.config['SESSION_TYPE'] = 'filesystem'

@app.route('/chat')
def chat():
    if 'history' not in session:
        session['history'] = []
    # 대화 처리
```

**Bottle 방식**:
Bottle은 내장 세션이 없어서 직접 구현하거나 **beaker** 같은 미들웨어 사용.

**간단한 대안**: 
폐쇄망에서 혼자 쓴다면 전역 변수로도 충분할 수 있다. 보안이 중요하면 제대로 된 **세션 관리**가 필요하지만.

```python
# 간단한 인메모리 세션
sessions = {}

def get_session(session_id):
    if session_id not in sessions:
        sessions[session_id] = {'history': [], 'context': {}}
    return sessions[session_id]
```

## 아키텍처 설계

이제 전체 구조를 그려보자.

![Architecture](/images/closed-net-arch.png)

### 계층 구조

```
┌─────────────────────────────────┐
│   웹 인터페이스 (HTML/JS)        │
│   - 입력창                       │
│   - 대화 표시                    │
└──────────────┬──────────────────┘
               │ HTTP Request
┌──────────────▼──────────────────┐
│   웹 서버 (Bottle/Flask)         │
│   - 라우팅                       │
│   - 세션 관리                    │
└──────────────┬──────────────────┘
               │
┌──────────────▼──────────────────┐
│   대화 관리자                    │
│   - 컨텍스트 로드                │
│   - 이력 관리                    │
│   - 플랜 생성                    │
└──────────────┬──────────────────┘
               │
       ┌───────┴────────┐
       │                │
┌──────▼─────┐  ┌──────▼──────┐
│ LLM 인터페이스│  │ 파일 시스템  │
│ (사내 GPT)  │  │   접근      │
└────────────┘  └─────────────┘
```

### 주요 모듈

**1. 웹 서버 모듈** (`app.py`)
- 라우트 정의 (/, /chat, /files, /context)
- 요청/응답 처리
- 세션 초기화

**2. 대화 관리 모듈** (`conversation.py`)
- `ConversationManager` 클래스
  - `add_message()`: 메시지 추가
  - `get_history()`: 이력 조회
  - `summarize_old_messages()`: 오래된 대화 요약
  - `clear_context()`: 컨텍스트 초기화

**3. LLM 인터페이스 모듈** (`llm_client.py`)
- `InternalGPTClient` 클래스
  - `__init__(api_endpoint, token)`: 초기화
  - `chat(messages)`: 일반 대화
  - `create_plan(context, question)`: **실행 계획 생성**
  - `summarize(text)`: 텍스트 요약

**4. 파일 시스템 모듈** (`filesystem.py`)
- `FileSystemManager` 클래스
  - `list_files(directory)`: 파일 목록
  - `read_file(path)`: 파일 읽기
  - `search_files(pattern)`: 파일 검색
  - `get_project_context()`: 프로젝트 구조 분석

**5. 컨텍스트 관리 모듈** (`context.py`)
- `ContextManager` 클래스
  - `load_context(name)`: 미리 정의된 컨텍스트 로드
  - `save_context(name, content)`: 컨텍스트 저장
  - `merge_contexts(contexts)`: 여러 컨텍스트 병합

### 데이터 흐름

1. **사용자 입력** → 웹 UI에서 질문 입력
2. **요청 수신** → 웹 서버가 POST 요청 받음
3. **세션 확인** → 세션 ID로 해당 사용자 대화 이력 로드
4. **컨텍스트 구성**:
   - 기본 컨텍스트 (프로젝트 정보, 규칙 등) 로드
   - 대화 이력 추가
   - 필요시 파일 내용 추가
5. **LLM 호출** → 구성된 컨텍스트와 함께 **사내 GPT** 호출
6. **계획 생성** → LLM이 구체적인 **실행 계획** 반환
7. **응답 저장** → 대화 이력에 추가
8. **결과 반환** → 웹 UI에 표시

### 구체적인 워크플로우 예시

**시나리오**: "이 프로젝트의 API 엔드포인트를 정리해줘"

1. 사용자가 웹에서 질문 입력
2. 서버가 요청 받아서 `ConversationManager`에 전달
3. `FileSystemManager`가 프로젝트 디렉토리 스캔
   - `app.py`, `routes.py` 같은 파일 찾기
   - 라우트 데코레이터 패턴 검색
4. `ContextManager`가 컨텍스트 구성:
   ```
   System: 당신은 Python 웹 개발 전문가입니다.
   Context: 현재 프로젝트는 Flask 기반이며 다음 파일들이 있습니다: ...
   History: [이전 대화 3개]
   User: 이 프로젝트의 API 엔드포인트를 정리해줘
   ```
5. `LLMClient`가 사내 GPT 호출
6. GPT 응답:
   ```
   프로젝트 API 엔드포인트 분석:
   
   1. GET /api/users - 사용자 목록 조회
   2. POST /api/users - 신규 사용자 생성
   3. GET /api/data - 데이터 조회
   ...
   
   다음 작업을 진행하시겠습니까?
   - API 문서 자동 생성
   - 테스트 코드 작성
   ```
7. 결과를 웹 UI에 표시

## 필요한 패키지 목록

폐쇄망 환경이라 사전에 모두 준비해야 한다.

**필수 패키지**:
- `bottle` 또는 `flask`: **웹 프레임워크**
- `requests`: **HTTP 클라이언트** (LLM API 호출)
- `pathlib`: 경로 관리 (Python 3.4+ 표준 라이브러리)

**선택적 패키지**:
- `flask-session`: Flask 세션 관리 (Flask 사용시)
- `python-dotenv`: 환경 변수 관리
- `markdown`: 응답을 HTML로 변환 (UI 개선용)
- `pygments`: **코드 하이라이팅**

**개발 도구**:
- `pytest`: 테스트
- `black`: **코드 포매팅**

전부 pip로 다운로드해서 오프라인 설치:
```bash
# 외부 환경에서
pip download bottle requests python-dotenv markdown -d packages/

# 폐쇄망에서
pip install --no-index --find-links=packages/ bottle requests
```

## 보안 고려사항

폐쇄망이라고 보안을 소홀히 하면 안 된다.

**1. 파일 시스템 접근 제한**
```python
ALLOWED_DIRECTORIES = ['/workspace/project', '/data/documents']

def is_safe_path(path):
    real_path = os.path.realpath(path)
    return any(real_path.startswith(allowed) for allowed in ALLOWED_DIRECTORIES)
```

**2. 입력 검증**
- **SQL Injection** 방지 (DB 사용시)
- **Path Traversal** 방지
- **XSS** 방지 (웹 출력시 이스케이핑)

**3. API 토큰 관리**
- 하드코딩 금지
- 환경 변수 또는 설정 파일 사용
- 파일 권한 적절히 설정 (600)

**4. 로깅**
- 모든 요청 기록
- 오류 추적
- 민감 정보 마스킹

## 성능 최적화 전략

**1. 캐싱**
- 자주 읽는 파일 내용 캐시
- LLM 응답 캐시 (동일 질문 재활용)
- 프로젝트 구조 캐시 (변경 감지 후 갱신)

**2. 비동기 처리**
- 파일 읽기 작업 병렬화
- **LLM 응답 스트리밍** (긴 응답 시 점진적 표시)

**3. 토큰 관리**
- 대화 이력 자동 요약
- 중요도 기반 컨텍스트 선별
- 최대 토큰 수 제한

## 확장 가능성

처음엔 단순하게 시작하지만, 나중을 위한 확장 포인트:

**1. 플러그인 시스템**
- 새로운 기능을 모듈로 추가
- **Git 연동**, 데이터베이스 쿼리, 테스트 실행 등

**2. 멀티모달 지원**
- 이미지 분석 (사내 GPT가 지원한다면)
- 문서 파싱 (PDF, DOCX)

**3. 협업 기능**
- 여러 사용자 지원
- 대화 공유
- 권한 관리

**4. CLI 모드**
- 웹 외에 터미널에서도 사용 가능
- 스크립트 자동화

## 구현 계획

이제 실제로 만들 차례다. 단계별로 나누면:

### Phase 1: 기본 구조 (1-2주)
- Bottle 기반 웹 서버 구축
- 간단한 웹 UI (입력창, 출력창)
- 사내 GPT API 연동 테스트
- 기본 대화 이력 관리

**목표**: "Hello, GPT" 수준의 대화 가능

### Phase 2: 컨텍스트 관리 (1주)
- 대화 이력 저장/로드
- 미리 정의된 컨텍스트 로드
- 토큰 제한 처리 (요약 또는 제거)

**목표**: 맥락 있는 대화 가능

### Phase 3: 파일 시스템 연동 (1-2주)
- 프로젝트 디렉토리 스캔
- 파일 읽기/검색 기능
- 파일 내용을 컨텍스트로 추가

**목표**: "이 파일 분석해줘" 같은 요청 처리

### Phase 4: 계획 생성 기능 (1주)
- 질문 → 실행 계획 자동 생성
- 계획을 단계별로 표시
- 사용자 확인 후 실행

**목표**: 복잡한 작업을 자동으로 단계화

### Phase 5: UI 개선 및 안정화 (1주)
- 반응형 UI
- **코드 하이라이팅**
- 에러 처리 강화
- 로깅 시스템

**목표**: 실무에서 안정적으로 사용 가능

## 예상 도전 과제

만들면서 마주칠 문제들:

**1. 사내 GPT API 스펙 파악**
- 문서가 없을 수도
- 직접 테스트하면서 파악해야 할 듯
- 요청/응답 포맷 확인
- 에러 처리 방식

**2. 토큰 제한 관리**
- 대화가 길어지면 컨텍스트가 너무 커짐
- 요약 품질이 중요
- 어떤 정보를 버리고 어떤 걸 남길지

**3. 파일 인코딩 문제**
- 한글 파일명, 한글 코드
- UTF-8, EUC-KR 혼재 가능
- 자동 감지 또는 설정 필요

**4. 윈도우 환경 특성**
- 경로 구분자 (`\` vs `/`)
- 권한 문제
- 방화벽 설정

**5. 성능 이슈**
- 대용량 파일 처리
- 많은 파일 스캔시 느려짐
- 캐싱 필수

## 테스트 전략

**단위 테스트**:
- 각 모듈별 독립 테스트
- LLM 호출은 목업 사용

**통합 테스트**:
- 전체 워크플로우 테스트
- 실제 사내 GPT 호출 (개발 환경)

**수동 테스트**:
- 다양한 질문 패턴 시도
- 엣지 케이스 확인
- 긴 대화 시뮬레이션

## 다음 포스팅 예고

이번 글에서는 전체적인 설계를 잡았다. 다음 포스팅에서는:

1. **Phase 1 구현**: 기본 웹 서버와 LLM 연동
2. **실제 코드**: Bottle + 사내 GPT 연동 예제
3. **웹 UI 구축**: 간단하지만 실용적인 인터페이스
4. **첫 대화 성공**: "Hello, GPT"부터 시작

폐쇄망 환경이라고 포기할 필요 없다. 제약이 많지만 창의적으로 접근하면 충분히 생산성을 끌어올릴 수 있다.

---

**핵심 포인트 정리**:

1. **경량 프레임워크 선택**: Bottle이나 Flask로 시작. 폐쇄망에선 의존성이 적을수록 좋다.

2. **대화 컨텍스트가 핵심**: LLM은 상태를 기억 못한다. 이력 관리가 전부다.

3. **파일 시스템 연동**: 로컬 코드를 읽어서 LLM에게 전달. 보안 주의.

4. **단계적 구현**: 한번에 다 만들지 말고 Phase별로 차근차근.

5. **확장성 고려**: 나중에 기능 추가하기 쉽게 모듈화.

다음 편에서는 실제 코드를 보여주며 본격적으로 시작해보자. 폐쇄망 개발자들이여, 희망을 잃지 말자!

#ClosedNetwork #CLI #Python #AI #GPT #Automation #Windows #Development #SoftwareArchitecture
