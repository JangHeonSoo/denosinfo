---
title: '오픈소스 AI의 반격'
description: 'OpenScholar와 DR Tulu-8B 등 오픈소스 모델이 거대 기업의 모델을 능가하는 현상과 학계의 가짜 인용 문제를 다룹니다.'
pubDate: 2026-02-05
category: 'AI'
tags: ['오픈소스AI', 'OpenScholar', 'GPT-4o', 'Ai2', 'AI할루시네이션', 'LLM', 'DRTulu', 'SLM']
heroImage: '/images/opensource-ai-hero.png'
---

# 80억 파라미터 모델이 GPT-4o를 이긴 날

지난주 Nature에 논문 하나가 올라왔다. **OpenScholar**라는 오픈소스 AI가 컴퓨터 과학 질문에서 **GPT-4o**를 이겼다는 내용이다. 정확도 51% 대 45%. 6%포인트? 별것 아닌 것 같지만, AI 벤치마크에서 이 정도면 꽤 큰 차이다.

## 작은 모델이 거인을 이기는 법

**OpenScholar**는 **Allen Institute for AI** (Ai2)와 5개 대학이 손잡고 만들었다. 4,500만 개의 오픈 액세스 논문을 검색한다. 한 번에 여러 논문을. 기존 LLM이 논문 하나씩 훑는 방식과는 완전히 다른 접근이다.

특이한 건 답변을 완성하기 전에 스스로 검증하는 과정을 거친다는 점. 이 자체 피드백 루프가 악명 높은 "가짜 인용"을 확 줄였다. 그리고 솔직히, 가짜 인용은 요즘 학계의 골칫덩이가 됐다.

## NeurIPS에서 발견된 100개 넘는 유령 인용

**GPTZero**가 올해 초 충격적인 분석을 내놨다. **NeurIPS 2025**에 실린 논문 중 100개 이상이 AI가 만들어낸 가짜 인용을 포함하고 있었다. 이 논문들은 24.52%의 채택률을 뚫었다. 각각 3~5명의 리뷰어 눈을 피했다.

![Ghost Citations in Academic Papers](/images/ghost-citations.png)

**ICLR 2026** 제출물? 마찬가지다. 50개 이상의 할루시네이션이 적발됐다.

한 연구자가 이 악몽을 정확히 묘사했다. "유령 인용이 실제 논문에 인용된다. 그 논문이 온라인에 올라간다. LLM이 그걸 발견하고 '아 이거 진짜인가 보다'라고 생각하고 또 인용한다." 악순환이 시작되는 거다.

## 1억 5,200만 달러의 베팅

돈이 **Ai2**로 몰리고 있다. 작년 8월, **NSF**와 **Nvidia**가 1억 5,200만 달러를 투자했다. 미국 정부의 AI 소프트웨어 인프라에 대한 첫 대규모 투자다.

마이크로소프트 공동창업자 폴 앨런이 2014년에 세운 연구소다. **OpenAI**나 **Anthropic**과 달리 **Ai2**는 모든 걸 공개한다. 가중치, 훈련 데이터, 코드, 평가 도구까지. 전부 "재현 가능한 연구"를 위해서다.

싱가포르 국립대학의 Min-Yen Kan 교수 말이 와닿는다. "**GPT-5**가 지금은 더 나을 수 있다. 하지만 그건 피어 리뷰를 거치지 않았다. 오픈소스 연구가 중요한 이유다."

## DR Tulu-8B: 80억 파라미터의 약자

11월에 **DR Tulu-8B**가 나왔다. 장문의 심층 연구 보고서를 위해 훈련된 최초의 오픈 모델이다. **OpenAI**의 **Deep Research**와 비교하면? 비슷하거나 더 나았다. 겨우 80억 파라미터로.

![AI Self-Verification HUD](/images/ai-verify.png)

비밀은 **RLER**, 진화하는 루브릭을 활용한 강화학습이다. 평가 기준이 모델과 함께 진화한다. 고정된 기준표가 없다. 모델이 배우면 기준도 업그레이드된다.

과학, 헬스케어, 일반 도메인 등 4개 벤치마크에서 **DR Tulu**는 기존 오픈 모델들을 8~42%포인트 차이로 눌렀다. 쿼리당 비용? 훨씬 저렴하다.

## 개발자에게 던지는 질문

2026년, "AI가 코드의 40% 이상을 작성하는" 시대에 우리는 뭘 믿어야 할까?

**OpenScholar**와 **DR Tulu-8B**가 분명히 보여준 게 있다. 크기가 전부가 아니다. 특정 도메인에 파인튜닝된 작은 모델이 거인을 이긴다. **AT&T**의 최고 데이터 책임자 Andy Markus의 말처럼, "파인튜닝된 **SLM**이 2026년의 대세가 될 것이다."

반면 MIT 연구원 Katherine Collins는 "디스킬링"을 걱정한다. 논문 요약이 너무 쉬워지면, 젊은 과학자들이 깊이 읽는 법을 배우지 않을 수 있다. 아이러니하게도 AI가 발전할수록 인간의 기본기가 더 중요해진다.

## 결론!!

1. **OpenScholar**가 **GPT-4o**를 이겼다 – CS 질문 정확도 51% vs 45%, 오픈소스도 경쟁력 있다
2. 가짜 인용이 판친다 – **NeurIPS 2025** 논문에서만 100개 이상 발견
3. 작은 모델의 반격 – **DR Tulu-8B** (80억 파라미터)가 **OpenAI Deep Research**와 대등; 파인튜닝된 **SLM**이 미래다

---

#OpenScholar #DRTulu #오픈소스AI #SLM #AI할루시네이션 #Ai2
